{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa48f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW: No keyword detected.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import dtw\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from mealpy.swarm_based.PSO import OriginalPSO\n",
    "from mealpy.utils.problem import Problem\n",
    "from mealpy.utils.space import FloatVar, IntegerVar\n",
    "import os\n",
    "import librosa.display\n",
    "from scipy.signal import butter, lfilter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define dataset paths\n",
    "BASE_DIR = \"C:\\\\Users\\\\naikg\\\\keyword-spotting\\\\data\\\\google_speech_recognition_v2\"\n",
    "FILE_LIST_PATH = os.path.join(BASE_DIR, \"testing_list.txt\")\n",
    "\n",
    "# Butterworth low-pass filter to reduce high-frequency noise\n",
    "def butter_lowpass_filter(data, cutoff=4000, sr=16000, order=5):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "# Read file paths and labels\n",
    "def read_file_paths_and_labels(file_list_path, base_directory):\n",
    "    file_paths, labels = [], []\n",
    "    \n",
    "    with open(file_list_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                label, filename = line.split('/', 1)\n",
    "                full_path = os.path.join(base_directory, line)\n",
    "                file_paths.append(full_path)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return file_paths, labels\n",
    "\n",
    "# Extract MFCC with noise reduction & pre-emphasis\n",
    "def extract_mfcc(file_path, sr=16000, n_mfcc=40):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        y = butter_lowpass_filter(y, cutoff=4000, sr=sr)\n",
    "        y = librosa.effects.preemphasis(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return mfcc.T  \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load and process dataset\n",
    "file_paths, labels = read_file_paths_and_labels(FILE_LIST_PATH, BASE_DIR)\n",
    "X_train = [extract_mfcc(fp) for fp in file_paths if extract_mfcc(fp) is not None]\n",
    "y_train = labels\n",
    "\n",
    "# Step 1: DTW-based initial keyword detection using sliding window\n",
    "def dtw_filter(query_audio, target_audio, threshold=300, window_size=10, step_size=50):\n",
    "    query_mfcc = extract_mfcc(query_audio)\n",
    "    target_mfcc = extract_mfcc(target_audio)\n",
    "    \n",
    "    if query_mfcc is None or target_mfcc is None:\n",
    "        return False\n",
    "    \n",
    "    for start in range(0, len(target_mfcc) - window_size, step_size):\n",
    "        segment = target_mfcc[start:start + window_size]\n",
    "        dtw_distance, _, _, _ = dtw.dtw(query_mfcc, segment, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "        if dtw_distance < threshold:\n",
    "            return True\n",
    "    \n",
    "    return False  \n",
    "\n",
    "# Step 2: BiLSTM model with PSO-optimized hyperparameters\n",
    "def create_bilstm_model(input_shape, lr, dropout):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dropout(dropout),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# PSO Objective Function\n",
    "def pso_objective(solution):\n",
    "    lr, dropout, epochs = solution\n",
    "    model = create_bilstm_model((100, 40), lr, dropout)\n",
    "    history = model.fit(np.array(X_train), np.array(y_train), epochs=int(epochs), batch_size=32, verbose=0)\n",
    "    return history.history['loss'][-1]  \n",
    "\n",
    "# Optimize with PSO\n",
    "def optimize_hyperparameters():\n",
    "    problem = Problem(\n",
    "        obj_func=pso_objective,\n",
    "        bounds=[FloatVar(0.0001, 0.01), FloatVar(0.1, 0.5), IntegerVar(5, 50)],\n",
    "        minmax=\"min\"\n",
    "    )\n",
    "    pso = OriginalPSO(epoch=20, pop_size=10)\n",
    "    best_solution = pso.solve(problem)\n",
    "    return best_solution.solution  \n",
    "\n",
    "# Train BiLSTM with optimized parameters\n",
    "def train_bilstm_model():\n",
    "    best_lr, best_dropout, best_epochs = optimize_hyperparameters()\n",
    "    model = create_bilstm_model((100, 40), best_lr, best_dropout)\n",
    "    model.fit(np.array(X_train), np.array(y_train), epochs=int(best_epochs), batch_size=32)\n",
    "    return model\n",
    "\n",
    "# Final QbE detection using BiLSTM\n",
    "def qbe_bilstm_detect(model, audio_file):\n",
    "    mfcc = extract_mfcc(audio_file)\n",
    "    mfcc = np.expand_dims(mfcc, axis=0)  \n",
    "    prediction = model.predict(mfcc)\n",
    "    return prediction > 0.5  \n",
    "\n",
    "if dtw_filter(\"cat.wav\", \"keyword_new_spotting_script_2000.wav\"):\n",
    "    print(\"DTW: Possible keyword detected! Refining with BiLSTM...\")\n",
    "    bilstm_model = train_bilstm_model()\n",
    "    found = qbe_bilstm_detect(bilstm_model, \"target_audio.wav\")\n",
    "    print(\"Final Detection:\", \"‚úÖ Keyword Found!\" if found else \"‚ùå No Keyword\")\n",
    "else:\n",
    "    print(\"DTW: No keyword detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988b49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Test audio file\n",
    "test_audio_path = \"keyword_new_spotting_script_5sec.wav\"\n",
    "test_mfcc = extract_mfcc(test_audio_path)  # Extract MFCC for test audio\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"keyword_detection_5sec.csv\"\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "missing_keywords = []\n",
    "\n",
    "# Loop over each keyword\n",
    "for keyword in keywords:\n",
    "    keyword_audio_path = f\"C:/Users/naikg/Ltsmkeyword/keyword_samples_wav/{keyword}.wav\"\n",
    "\n",
    "    if os.path.exists(keyword_audio_path):\n",
    "        print(f\"üîç Processing '{keyword}'...\")\n",
    "        keyword_mfcc = extract_mfcc(keyword_audio_path)\n",
    "        print(keyword_mfcc)# Extract MFCC for keyword\n",
    "        result = detect_keywords_dtw(test_mfcc, keyword_mfcc, keyword)  # Detect occurrences\n",
    "        results.append(result)\n",
    "    else:\n",
    "        missing_keywords.append(keyword)\n",
    "\n",
    "# Save results to CSV\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_filename, index=False, mode=\"w\")  # Overwrites the CSV for fresh results\n",
    "    print(f\"\\n Detection results saved to '{csv_filename}'\")\n",
    "\n",
    "# Report missing keywords\n",
    "if missing_keywords:\n",
    "    print(\"\\n Missing keyword files:\")\n",
    "    print(\", \".join(missing_keywords))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
