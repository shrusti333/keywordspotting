{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c4086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a054f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Scikit-learn Version:\", sklearn.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8c30e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_speech_commands_data.py already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# URL to download the script from\n",
    "branch = 'main'  # or whichever branch you want to use\n",
    "url = f'https://raw.githubusercontent.com/NVIDIA/NeMo/{branch}/scripts/dataset_processing/process_speech_commands_data.py'\n",
    "file_path = 'process_speech_commands_data.py'\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"{file_path} not found. Downloading from {url}...\")\n",
    "    \n",
    "    # Use urllib to download the file\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "    \n",
    "    print(f\"{file_path} downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"{file_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dda6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7533668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.signal import butter, lfilter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define dataset paths\n",
    "BASE_DIR = \"C:\\\\Users\\\\naikg\\\\keyword-spotting\\\\data\\\\google_speech_recognition_v2\"\n",
    "FILE_LIST_PATH = os.path.join(BASE_DIR, \"testing_list.txt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c67c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Butterworth low-pass filter to reduce high-frequency noise\n",
    "def butter_lowpass_filter(data, cutoff=4000, sr=16000, order=5):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return lfilter(b, a, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e9038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file paths and labels\n",
    "def read_file_paths_and_labels(file_list_path, base_directory):\n",
    "    file_paths, labels = [], []\n",
    "    \n",
    "    with open(file_list_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove whitespace\n",
    "            if line:\n",
    "                label, filename = line.split('/', 1)\n",
    "                full_path = os.path.join(base_directory, line)\n",
    "                file_paths.append(full_path)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return file_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1bc542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract MFCC with noise reduction & pre-emphasis\n",
    "def extract_mfcc(file_path, sr=16000, n_mfcc=40):\n",
    "    try:\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        \n",
    "        # Apply noise reduction\n",
    "        y = butter_lowpass_filter(y, cutoff=4000, sr=sr)\n",
    "        \n",
    "        # Apply pre-emphasis filter\n",
    "        y = librosa.effects.preemphasis(y)\n",
    "        \n",
    "        # Extract MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        return mfcc.T  # Shape: (time_steps, features)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3186105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load all audio files and extract MFCC features\n",
    "def load_and_process_audio(file_paths):\n",
    "    mfcc_features, labels_list = [], []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        mfcc = extract_mfcc(file_path)\n",
    "        if mfcc is not None:\n",
    "            mfcc_features.append(mfcc)\n",
    "    \n",
    "    # Pad sequences to uniform shape\n",
    "    mfcc_features = pad_sequences(mfcc_features, padding=\"post\", dtype=\"float32\")\n",
    "    \n",
    "    return np.array(mfcc_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e917503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e749dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11005 audio files with MFCC shape: (32, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read file paths\n",
    "file_paths, labels = read_file_paths_and_labels(FILE_LIST_PATH, BASE_DIR)\n",
    "\n",
    "# Load and extract MFCC features\n",
    "X = load_and_process_audio(file_paths)\n",
    "\n",
    "# Print shape\n",
    "print(f\"Processed {X.shape[0]} audio files with MFCC shape: {X.shape[1:]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e115c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdeeea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e06823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8804, 32, 40)\n",
      "y_train shape: (8804, 35)\n",
      "Epoch 1/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 61ms/step - accuracy: 0.0696 - loss: 3.6328 - val_accuracy: 0.2731 - val_loss: 2.6439\n",
      "Epoch 2/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - accuracy: 0.2865 - loss: 2.5151 - val_accuracy: 0.4952 - val_loss: 1.6953\n",
      "Epoch 3/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - accuracy: 0.4384 - loss: 1.9079 - val_accuracy: 0.5988 - val_loss: 1.3675\n",
      "Epoch 4/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - accuracy: 0.5296 - loss: 1.5773 - val_accuracy: 0.6629 - val_loss: 1.1944\n",
      "Epoch 5/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - accuracy: 0.5858 - loss: 1.3557 - val_accuracy: 0.7147 - val_loss: 0.9821\n",
      "Epoch 6/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.6343 - loss: 1.2069 - val_accuracy: 0.7238 - val_loss: 0.9271\n",
      "Epoch 7/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - accuracy: 0.6504 - loss: 1.1869 - val_accuracy: 0.6583 - val_loss: 1.1547\n",
      "Epoch 8/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.6916 - loss: 1.0348 - val_accuracy: 0.7424 - val_loss: 0.8233\n",
      "Epoch 9/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - accuracy: 0.7109 - loss: 0.9499 - val_accuracy: 0.7737 - val_loss: 0.7380\n",
      "Epoch 10/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.7053 - loss: 0.9524 - val_accuracy: 0.7878 - val_loss: 0.7260\n",
      "Epoch 11/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7399 - loss: 0.8623 - val_accuracy: 0.7737 - val_loss: 0.7860\n",
      "Epoch 12/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 67ms/step - accuracy: 0.7494 - loss: 0.8355 - val_accuracy: 0.7833 - val_loss: 0.7225\n",
      "Epoch 13/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7555 - loss: 0.8175 - val_accuracy: 0.7892 - val_loss: 0.6878\n",
      "Epoch 14/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 66ms/step - accuracy: 0.7564 - loss: 0.8127 - val_accuracy: 0.8078 - val_loss: 0.6427\n",
      "Epoch 15/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.7777 - loss: 0.7469 - val_accuracy: 0.8255 - val_loss: 0.5882\n",
      "Epoch 16/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7885 - loss: 0.6827 - val_accuracy: 0.8224 - val_loss: 0.6135\n",
      "Epoch 17/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7975 - loss: 0.6645 - val_accuracy: 0.8083 - val_loss: 0.6392\n",
      "Epoch 18/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 64ms/step - accuracy: 0.8045 - loss: 0.6312 - val_accuracy: 0.8278 - val_loss: 0.5758\n",
      "Epoch 19/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.8196 - loss: 0.5901 - val_accuracy: 0.8233 - val_loss: 0.6116\n",
      "Epoch 20/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.8127 - loss: 0.6171 - val_accuracy: 0.8337 - val_loss: 0.5772\n",
      "Epoch 21/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.8169 - loss: 0.5937 - val_accuracy: 0.8319 - val_loss: 0.5649\n",
      "Epoch 22/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - accuracy: 0.8280 - loss: 0.5725 - val_accuracy: 0.8264 - val_loss: 0.5690\n",
      "Epoch 23/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.8313 - loss: 0.5736 - val_accuracy: 0.8519 - val_loss: 0.5347\n",
      "Epoch 24/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.8261 - loss: 0.5782 - val_accuracy: 0.8396 - val_loss: 0.5392\n",
      "Epoch 25/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.8364 - loss: 0.5374 - val_accuracy: 0.8392 - val_loss: 0.5631\n",
      "Epoch 26/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 55ms/step - accuracy: 0.8510 - loss: 0.4950 - val_accuracy: 0.8437 - val_loss: 0.5416\n",
      "Epoch 27/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - accuracy: 0.8498 - loss: 0.4869 - val_accuracy: 0.8546 - val_loss: 0.5357\n",
      "Epoch 28/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - accuracy: 0.8621 - loss: 0.4643 - val_accuracy: 0.8555 - val_loss: 0.5125\n",
      "Epoch 29/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - accuracy: 0.8606 - loss: 0.4626 - val_accuracy: 0.8487 - val_loss: 0.5369\n",
      "Epoch 30/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.8632 - loss: 0.4454 - val_accuracy: 0.8501 - val_loss: 0.5272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">173,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,155</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m173,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m1,155\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,031,147</span> (3.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,031,147\u001b[0m (3.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">343,459</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m343,459\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">686,920</span> (2.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m686,920\u001b[0m (2.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ensure X and labels are properly defined before proceeding\n",
    "assert 'X' in locals() and 'labels' in locals(), \"Make sure X and labels are defined before using them.\"\n",
    "\n",
    "# Encode labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)  # Convert text labels to numbers\n",
    "y = to_categorical(y)  # Convert to one-hot encoding\n",
    "\n",
    "# Train-Test Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure X_train has the correct shape\n",
    "print(\"X_train shape:\", X_train.shape)  # Should be (num_samples, time_steps, num_features)\n",
    "print(\"y_train shape:\", y_train.shape)  # Should be (num_samples, num_classes)\n",
    "\n",
    "# Define LSTM/BiLSTM Model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),  # Correct way to define input\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Bidirectional(LSTM(64, return_sequences=False)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Output layer (multi-class classification)\n",
    "])\n",
    "\n",
    "# Compile model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=32)\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"keyword_spotting_model.h5\")\n",
    "\n",
    "# Save the label encoder to retrieve labels during prediction\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508043eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff5cc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy: 86.40%\n",
      "Final Validation Accuracy: 85.01%\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy', color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Accuracy Over Epochs (LSTM/BiLSTM Model)\")\n",
    "plt.show()\n",
    "\n",
    "# Print final accuracy\n",
    "train_acc = history.history['accuracy'][-1] * 100\n",
    "val_acc = history.history['val_accuracy'][-1] * 100\n",
    "print(f\"Final Training Accuracy: {train_acc:.2f}%\")\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ebc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"keyword_spotting_model.h5\")\n",
    "\n",
    "# Real-time inference function\n",
    "def recognize_keyword(duration=1, sr=16000, threshold=0.8):\n",
    "    print(\"Listening for keywords...\")\n",
    "\n",
    "    while True:\n",
    "        # Record audio\n",
    "        audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype='float32')\n",
    "        sd.wait()\n",
    "\n",
    "        # Convert to 1D array\n",
    "        audio = audio.flatten()\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc = extract_mfcc(audio)\n",
    "\n",
    "        # Pad sequence\n",
    "        mfcc = pad_sequences([mfcc], maxlen=X_train.shape[1], padding=\"post\", dtype=\"float32\")\n",
    "\n",
    "        # Get prediction\n",
    "        prediction = model.predict(mfcc)\n",
    "        if prediction[0][1] > threshold:\n",
    "            print(f\"True - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Run real-time detection\n",
    "recognize_keyword()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ec1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Test files directory\n",
    "TEST_FILES_PATH = \"test_audio_files/\"\n",
    "\n",
    "# Function to test accuracy on multiple audio files\n",
    "def evaluate_model():\n",
    "    total_keywords = 0\n",
    "    correct_detections = 0\n",
    "\n",
    "    for file in os.listdir(TEST_FILES_PATH):\n",
    "        file_path = os.path.join(TEST_FILES_PATH, file)\n",
    "        audio, sr = librosa.load(file_path, sr=16000)\n",
    "        mfcc = extract_mfcc(audio)\n",
    "\n",
    "        # Pad sequence\n",
    "        mfcc = pad_sequences([mfcc], maxlen=X_train.shape[1], padding=\"post\", dtype=\"float32\")\n",
    "\n",
    "        # Predict\n",
    "        prediction = model.predict(mfcc)\n",
    "        detected = prediction[0][1] > 0.8\n",
    "\n",
    "        # Check ground truth (assume each file contains exactly 20 keywords)\n",
    "        if detected:\n",
    "            correct_detections += 1\n",
    "        total_keywords += 20\n",
    "\n",
    "        accuracy = (correct_detections / total_keywords) * 100\n",
    "        print(f\"Accuracy for {file}: {accuracy:.2f}%\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cf109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "feee3010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded and split successfully!\n",
      "X_train shape: (8804, 32, 40), y_train shape: (8804, 35)\n",
      "X_test shape: (2201, 32, 40), y_test shape: (2201, 35)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from pyswarm import pso\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "from mealpy.swarm_based.GWO import OriginalGWO\n",
    "\n",
    "# 🔹 Load your dataset here\n",
    "# Example: X = np.load('features.npy')  # Load precomputed MFCC features\n",
    "# Example: labels = np.load('labels.npy')  # Load corresponding labels\n",
    "\n",
    "if 'X' not in locals() or 'labels' not in locals():\n",
    "    raise ValueError(\"Dataset not loaded. Define X (features) and labels before proceeding.\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)  \n",
    "y = to_categorical(y)  # Convert labels to one-hot encoding\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"✅ Data loaded and split successfully!\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178ce0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function (shared across all optimizers)\n",
    "def train_and_evaluate(params):\n",
    "    learning_rate, dropout_rate = params\n",
    "    model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),  # Correct way to define input\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Bidirectional(LSTM(64, return_sequences=False)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Output layer (multi-class classification)\n",
    "])\n",
    "\n",
    "   \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Train for a few epochs to evaluate\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    return -max(history.history['val_accuracy'])  # We minimize negative accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cb6096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 3\n"
     ]
    }
   ],
   "source": [
    "# **Train Model 1: Using PSO**\n",
    "start_time = time.time()\n",
    "lb = [0.0001, 0.1]\n",
    "ub = [0.01, 0.5]\n",
    "best_params_pso, _ = pso(train_and_evaluate, lb, ub, swarmsize=5, maxiter=3)\n",
    "pso_time = time.time() - start_time\n",
    "best_lr_pso, best_dropout_pso = best_params_pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1070f9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5405e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Train Final Models Using Optimized Parameters**\n",
    "def build_and_train_model(learning_rate, dropout_rate, optimizer_name):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),  # ✅ Fixed input layer\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Bidirectional(LSTM(64, return_sequences=False)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Train Final Model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(f\"keyword_spotting_model_{optimizer_name}.h5\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a41d9dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 75ms/step - accuracy: 0.0754 - loss: 3.6146 - val_accuracy: 0.3398 - val_loss: 2.4225\n",
      "Epoch 2/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 72ms/step - accuracy: 0.2997 - loss: 2.4159 - val_accuracy: 0.5248 - val_loss: 1.6411\n",
      "Epoch 3/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - accuracy: 0.4593 - loss: 1.8207 - val_accuracy: 0.6161 - val_loss: 1.3121\n",
      "Epoch 4/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.5652 - loss: 1.4720 - val_accuracy: 0.6724 - val_loss: 1.1310\n",
      "Epoch 5/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 68ms/step - accuracy: 0.6268 - loss: 1.2414 - val_accuracy: 0.7110 - val_loss: 0.9709\n",
      "Epoch 6/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - accuracy: 0.6463 - loss: 1.1503 - val_accuracy: 0.7238 - val_loss: 0.9057\n",
      "Epoch 7/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - accuracy: 0.6833 - loss: 1.0348 - val_accuracy: 0.7542 - val_loss: 0.8343\n",
      "Epoch 8/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - accuracy: 0.7043 - loss: 0.9804 - val_accuracy: 0.7315 - val_loss: 0.9187\n",
      "Epoch 9/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.7106 - loss: 0.9467 - val_accuracy: 0.7751 - val_loss: 0.7211\n",
      "Epoch 10/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.7383 - loss: 0.8589 - val_accuracy: 0.7728 - val_loss: 0.7419\n",
      "Epoch 11/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - accuracy: 0.7404 - loss: 0.8481 - val_accuracy: 0.8060 - val_loss: 0.6774\n",
      "Epoch 12/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 68ms/step - accuracy: 0.7523 - loss: 0.8285 - val_accuracy: 0.8101 - val_loss: 0.6631\n",
      "Epoch 13/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.7699 - loss: 0.7594 - val_accuracy: 0.8105 - val_loss: 0.6287\n",
      "Epoch 14/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 0.7848 - loss: 0.7012 - val_accuracy: 0.8196 - val_loss: 0.5795\n",
      "Epoch 15/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - accuracy: 0.8049 - loss: 0.6225 - val_accuracy: 0.8160 - val_loss: 0.6275\n",
      "Epoch 16/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - accuracy: 0.7838 - loss: 0.6899 - val_accuracy: 0.8151 - val_loss: 0.6167\n",
      "Epoch 17/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.8149 - loss: 0.6141 - val_accuracy: 0.8269 - val_loss: 0.5753\n",
      "Epoch 18/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - accuracy: 0.8254 - loss: 0.5823 - val_accuracy: 0.8242 - val_loss: 0.5941\n",
      "Epoch 19/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 64ms/step - accuracy: 0.8195 - loss: 0.5958 - val_accuracy: 0.8442 - val_loss: 0.5424\n",
      "Epoch 20/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 67ms/step - accuracy: 0.8263 - loss: 0.5448 - val_accuracy: 0.8442 - val_loss: 0.5575\n",
      "Epoch 21/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.8362 - loss: 0.5406 - val_accuracy: 0.8355 - val_loss: 0.5637\n",
      "Epoch 22/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 68ms/step - accuracy: 0.8348 - loss: 0.5180 - val_accuracy: 0.8501 - val_loss: 0.5315\n",
      "Epoch 23/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.8508 - loss: 0.4756 - val_accuracy: 0.8573 - val_loss: 0.5190\n",
      "Epoch 24/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - accuracy: 0.8507 - loss: 0.4858 - val_accuracy: 0.8387 - val_loss: 0.5844\n",
      "Epoch 25/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 69ms/step - accuracy: 0.8474 - loss: 0.4854 - val_accuracy: 0.8532 - val_loss: 0.5190\n",
      "Epoch 26/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 0.8623 - loss: 0.4500 - val_accuracy: 0.8496 - val_loss: 0.5341\n",
      "Epoch 27/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - accuracy: 0.8571 - loss: 0.4556 - val_accuracy: 0.8596 - val_loss: 0.5182\n",
      "Epoch 28/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - accuracy: 0.8644 - loss: 0.4372 - val_accuracy: 0.8451 - val_loss: 0.5731\n",
      "Epoch 29/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 0.8718 - loss: 0.4139 - val_accuracy: 0.8510 - val_loss: 0.5251\n",
      "Epoch 30/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 0.8720 - loss: 0.4076 - val_accuracy: 0.8537 - val_loss: 0.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history_pso = build_and_train_model(best_lr_pso, best_dropout_pso, \"pso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a65e2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_and_evaluate(params, X_train, y_train, X_test, y_test):\n",
    "    learning_rate, dropout_rate = params\n",
    "\n",
    "    # Ensure params are valid\n",
    "    if not (0.0001 <= learning_rate <= 0.01 and 0.1 <= dropout_rate <= 0.5):\n",
    "        return 1e6  # Large loss for invalid values\n",
    "\n",
    "    if X_train is None or y_train is None:\n",
    "        return 1e6  # Large loss if data is missing\n",
    "\n",
    "    # Model Definition\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Bidirectional(LSTM(64, return_sequences=False)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer\n",
    "    ])\n",
    "\n",
    "    # Compile Model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Train Model (Shorter Training)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=16, verbose=0)\n",
    "\n",
    "    # Ensure valid accuracy\n",
    "    val_acc = history.history.get('val_accuracy', [0])\n",
    "    return -max(val_acc) if val_acc else 1e6  # Minimize loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fcdcf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best solution found:                                                                           \n",
      " [0.00306896 0.22745524]\n",
      "\n",
      " Objective function:\n",
      " -0.6201726198196411\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: GA is terminated due to the maximum number of iterations without improvement was met!"
     ]
    }
   ],
   "source": [
    "\n",
    "# **Train Model 2: Using GA**\n",
    "start_time = time.time()\n",
    "var_bound = np.array([[0.0001, 0.01], [0.1, 0.5]])\n",
    "# GA Parameters\n",
    "algorithm_param = {\n",
    "    'max_num_iteration': 20,  # Increase iterations for better search\n",
    "    'population_size': 20,    # Larger population size for better exploration\n",
    "    'mutation_probability': 0.1,\n",
    "    'elit_ratio': 0.1,        # More elite selection\n",
    "    'crossover_probability': 0.5,\n",
    "    'parents_portion': 0.3,\n",
    "    'crossover_type': 'uniform',\n",
    "    'max_iteration_without_improv': 5  # More patience for improvements\n",
    "}\n",
    "# Start training using GA\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the Genetic Algorithm optimization\n",
    "model_ga = ga(\n",
    "    function=lambda p: train_and_evaluate(p, X_train, y_train, X_test, y_test),  # Wrap function\n",
    "    dimension=2,\n",
    "    variable_type='real',\n",
    "    variable_boundaries=np.array([[0.0001, 0.01], [0.1, 0.5]]),\n",
    "    algorithm_parameters={\n",
    "        'max_num_iteration': 5,\n",
    "        'population_size': 10,\n",
    "        'mutation_probability': 0.1,\n",
    "        'elit_ratio': 0.01,\n",
    "        'crossover_probability': 0.5,\n",
    "        'parents_portion': 0.3,\n",
    "        'crossover_type': 'uniform',\n",
    "        'max_iteration_without_improv': 2\n",
    "    },\n",
    "    function_timeout=300  # Increase timeout\n",
    ")\n",
    "\n",
    "# Run Genetic Algorithm Optimization\n",
    "model_ga.run()\n",
    "\n",
    "# Get best parameters\n",
    "best_lr_ga, best_dropout_ga = model_ga.output_dict['variable']\n",
    "\n",
    "\n",
    "ga_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94352e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67770daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 63ms/step - accuracy: 0.1415 - loss: 3.2403 - val_accuracy: 0.4162 - val_loss: 1.9991\n",
      "Epoch 2/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.4233 - loss: 1.9227 - val_accuracy: 0.5525 - val_loss: 1.5010\n",
      "Epoch 3/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.5329 - loss: 1.5095 - val_accuracy: 0.6688 - val_loss: 1.1272\n",
      "Epoch 4/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - accuracy: 0.5787 - loss: 1.3972 - val_accuracy: 0.6065 - val_loss: 1.3017\n",
      "Epoch 5/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.6191 - loss: 1.2684 - val_accuracy: 0.6329 - val_loss: 1.1760\n",
      "Epoch 6/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.6421 - loss: 1.2009 - val_accuracy: 0.7383 - val_loss: 0.8961\n",
      "Epoch 7/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.6674 - loss: 1.1061 - val_accuracy: 0.7206 - val_loss: 0.8844\n",
      "Epoch 8/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - accuracy: 0.6598 - loss: 1.1174 - val_accuracy: 0.7378 - val_loss: 0.8427\n",
      "Epoch 9/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - accuracy: 0.6775 - loss: 1.0686 - val_accuracy: 0.7160 - val_loss: 0.9206\n",
      "Epoch 10/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.6800 - loss: 1.0558 - val_accuracy: 0.7160 - val_loss: 0.9372\n",
      "Epoch 11/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7002 - loss: 0.9899 - val_accuracy: 0.7360 - val_loss: 0.8559\n",
      "Epoch 12/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7154 - loss: 0.9461 - val_accuracy: 0.7756 - val_loss: 0.7594\n",
      "Epoch 13/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.7357 - loss: 0.8877 - val_accuracy: 0.7697 - val_loss: 0.7765\n",
      "Epoch 14/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7440 - loss: 0.8723 - val_accuracy: 0.7969 - val_loss: 0.6887\n",
      "Epoch 15/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7528 - loss: 0.8174 - val_accuracy: 0.8028 - val_loss: 0.6485\n",
      "Epoch 16/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7466 - loss: 0.8406 - val_accuracy: 0.7987 - val_loss: 0.6897\n",
      "Epoch 17/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7586 - loss: 0.8144 - val_accuracy: 0.8083 - val_loss: 0.6743\n",
      "Epoch 18/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.7538 - loss: 0.8153 - val_accuracy: 0.8101 - val_loss: 0.6517\n",
      "Epoch 19/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7367 - loss: 0.8812 - val_accuracy: 0.7869 - val_loss: 0.7357\n",
      "Epoch 20/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 59ms/step - accuracy: 0.7736 - loss: 0.7501 - val_accuracy: 0.8065 - val_loss: 0.6651\n",
      "Epoch 21/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7810 - loss: 0.7297 - val_accuracy: 0.8201 - val_loss: 0.6396\n",
      "Epoch 22/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7833 - loss: 0.7262 - val_accuracy: 0.8323 - val_loss: 0.5895\n",
      "Epoch 23/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7864 - loss: 0.7140 - val_accuracy: 0.8024 - val_loss: 0.6596\n",
      "Epoch 24/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.8074 - loss: 0.6376 - val_accuracy: 0.8051 - val_loss: 0.6553\n",
      "Epoch 25/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7727 - loss: 0.7443 - val_accuracy: 0.8410 - val_loss: 0.5560\n",
      "Epoch 26/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7940 - loss: 0.6757 - val_accuracy: 0.8323 - val_loss: 0.5769\n",
      "Epoch 27/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7901 - loss: 0.6895 - val_accuracy: 0.8205 - val_loss: 0.6188\n",
      "Epoch 28/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.8005 - loss: 0.6764 - val_accuracy: 0.8364 - val_loss: 0.5709\n",
      "Epoch 29/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.7991 - loss: 0.6701 - val_accuracy: 0.8269 - val_loss: 0.6028\n",
      "Epoch 30/30\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 62ms/step - accuracy: 0.7974 - loss: 0.6717 - val_accuracy: 0.8346 - val_loss: 0.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history_ga = build_and_train_model(best_lr_ga, best_dropout_ga, \"ga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9fcdeb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m gwo \u001b[38;5;241m=\u001b[39m OriginalGWO()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Solve the problem\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m best_solution_gwo \u001b[38;5;241m=\u001b[39m gwo\u001b[38;5;241m.\u001b[39msolve(problem, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m gwo_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract best learning rate and dropout\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\optimizer.py:237\u001b[0m, in \u001b[0;36mOptimizer.solve\u001b[1;34m(self, problem, mode, n_workers, termination, starting_solutions, seed)\u001b[0m\n\u001b[0;32m    234\u001b[0m time_epoch \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m## Evolve method will be called in child class\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevolve(epoch)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# Update global best solution, the population is sorted or not depended on algorithm's strategy\u001b[39;00m\n\u001b[0;32m    240\u001b[0m pop_temp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_global_best_agent(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\swarm_based\\GWO.py:81\u001b[0m, in \u001b[0;36mOriginalGWO.evolve\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     79\u001b[0m     pop_new\u001b[38;5;241m.\u001b[39mappend(agent)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAVAILABLE_MODES:\n\u001b[1;32m---> 81\u001b[0m         agent\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_target(pos_new)\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_better_agent(agent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mminmax)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAVAILABLE_MODES:\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\optimizer.py:406\u001b[0m, in \u001b[0;36mOptimizer.get_target\u001b[1;34m(self, solution, counted)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counted:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfe_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mget_target(solution)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\utils\\problem.py:200\u001b[0m, in \u001b[0;36mProblem.get_target\u001b[1;34m(self, solution)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_target\u001b[39m(\u001b[38;5;28mself\u001b[39m, solution: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Target:\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m        solution: The real-value solution\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m        The target object\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj_func(solution)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Target(objectives\u001b[38;5;241m=\u001b[39mobjs, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj_weights)\n",
      "Cell \u001b[1;32mIn[70], line 9\u001b[0m, in \u001b[0;36mgwo_objective\u001b[1;34m(solution)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgwo_objective\u001b[39m(solution):\n\u001b[0;32m      8\u001b[0m     lr, dropout \u001b[38;5;241m=\u001b[39m solution  \u001b[38;5;66;03m# Extract the learning rate and dropout\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_and_evaluate(solution, X_train, y_train, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[58], line 38\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(params, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Train Model (Shorter Training)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Ensure valid accuracy\u001b[39;00m\n\u001b[0;32m     41\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mealpy.swarm_based.GWO import OriginalGWO\n",
    "from mealpy.utils.problem import Problem\n",
    "from mealpy.utils.space import FloatVar\n",
    "import time\n",
    "\n",
    "# Ensure train_and_evaluate() takes all required parameters\n",
    "def gwo_objective(solution):\n",
    "    lr, dropout = solution  # Extract the learning rate and dropout\n",
    "    return train_and_evaluate(solution, X_train, y_train, X_test, y_test)  # Pass the full dataset\n",
    "\n",
    "# Define the problem correctly using FloatVar\n",
    "problem = Problem(\n",
    "    obj_func=gwo_objective,   # Objective function reference\n",
    "    bounds=[FloatVar(0.0001, 0.1), FloatVar(0.01, 0.5)],  # Define bounds with FloatVar\n",
    "    minmax=\"min\",             # Minimize loss\n",
    "    log_to=None               # Avoid extra logging\n",
    ")\n",
    "\n",
    "# Initialize GWO optimizer\n",
    "start_time = time.time()\n",
    "gwo = OriginalGWO()\n",
    "\n",
    "# Solve the problem\n",
    "best_solution_gwo = gwo.solve(problem, mode=\"single\", n_workers=1)\n",
    "\n",
    "gwo_time = time.time() - start_time\n",
    "\n",
    "# Extract best learning rate and dropout\n",
    "best_lr_gwo, best_dropout_gwo = best_solution_gwo.solution\n",
    "\n",
    "print(f\"✅ Best GWO parameters: Learning Rate = {best_lr_gwo}, Dropout = {best_dropout_gwo}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # **Train Model 3: Using GWO**\n",
    "# start_time = time.time()\n",
    "# gwo = OriginalGWO(obj_func=train_and_evaluate, lb=lb, ub=ub, problem_size=2, batch_size=5, epoch=5)\n",
    "# best_solution_gwo, best_fitness_gwo = gwo.solve()\n",
    "\n",
    "# gwo_time = time.time() - start_time\n",
    "# best_lr_gwo, best_dropout_gwo = best_solution_gwo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf22dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_gwo = build_and_train_model(best_lr_gwo, best_dropout_gwo, \"gwo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd339ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "# history_pso = build_and_train_model(best_lr_pso, best_dropout_pso, \"pso\")\n",
    "# history_ga = build_and_train_model(best_lr_ga, best_dropout_ga, \"ga\")\n",
    "# history_gwo = build_and_train_model(best_lr_gwo, best_dropout_gwo, \"gwo\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(histories, names):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history, name in zip(histories, names):\n",
    "        plt.plot(history.history['val_accuracy'], label=f\"{name}\")\n",
    "    plt.title('Validation Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history, name in zip(histories, names):\n",
    "        plt.plot(history.history['val_loss'], label=f\"{name}\")\n",
    "    plt.title('Validation Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fa137",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([history_pso, history_ga, history_gwo], [\"PSO\", \"GA\", \"GWO\"])\n",
    "\n",
    "# Print Training Times\n",
    "print(f\"PSO Training Time: {pso_time:.2f} sec\")\n",
    "print(f\"GA Training Time: {ga_time:.2f} sec\")\n",
    "print(f\"GWO Training Time: {gwo_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dc643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize the Artificial Bee Colony (ABC) optimizer\n",
      "Solve the problem\n"
     ]
    }
   ],
   "source": [
    "from mealpy.utils.problem import Problem\n",
    "from mealpy.swarm_based.ABC import OriginalABC\n",
    "from mealpy.utils.space import FloatVar\n",
    "\n",
    "# Define the objective function\n",
    "def abc_objective(solution):\n",
    "    lr, dropout = solution  # Extract hyperparameters\n",
    "    return train_and_evaluate(solution, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Define the problem using Mealpy's Problem class\n",
    "problem = Problem(\n",
    "    obj_func=abc_objective,\n",
    "    bounds=[FloatVar(0.0001, 0.1), FloatVar(0.01, 0.5)],  # Correct bounds using FloatVar\n",
    "    minmax=\"min\",  # Minimize the loss\n",
    "    log_to=None\n",
    ")\n",
    "print(\"Initialize the Artificial Bee Colony (ABC) optimizer\")\n",
    "# Initialize the Artificial Bee Colony (ABC) optimizer\n",
    "abc = OriginalABC(epoch=30, pop_size=30, limit=5)\n",
    "print(\"Solve the problem\")\n",
    "# Solve the problem\n",
    "best_solution_abc = abc.solve(problem, mode=\"process\", n_workers=8)\n",
    "\n",
    "\n",
    "# Extract best parameters\n",
    "best_lr_abc, best_dropout_abc = best_solution_abc.solution\n",
    "print(f\"Best Learning Rate: {best_lr_abc}, Best Dropout: {best_dropout_abc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1709d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231e20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65a231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b890e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96609683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_abc = build_and_train_model(best_lr_abc, best_dropout_abc, \"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([history_pso,history_abc, history_ga, history_gwo], [\"PSO\",\"ABC\", \"GA\", \"GWO\"])\n",
    "print(f\"PSO Training Time: {pso_time:.2f} sec\")\n",
    "# Print Training Times\n",
    "print(f\"ABC Training Time: {abc_time:.2f} sec\")\n",
    "print(f\"GA Training Time: {ga_time:.2f} sec\")\n",
    "print(f\"GWO Training Time: {gwo_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f6a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "from mealpy.swarm_based.GWO import OriginalGWO\n",
    "from mealpy.swarm_based.ABC import OriginalABC  # Replacing PSO with ABC\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)  \n",
    "y = to_categorical(y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define training function (shared across all optimizers)\n",
    "def train_and_evaluate(params):\n",
    "    learning_rate, dropout_rate = params\n",
    "\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Bidirectional(LSTM(64, return_sequences=False)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    return -max(history.history['val_accuracy'])  # We minimize negative accuracy\n",
    "\n",
    "# **Train Model 1: Using ABC (Artificial Bee Colony)**\n",
    "start_time = time.time()\n",
    "lb = [0.0001, 0.1]\n",
    "ub = [0.01, 0.5]\n",
    "abc = OriginalABC(obj_func=train_and_evaluate, lb=lb, ub=ub, problem_size=2, batch_size=5, epoch=5)\n",
    "best_solution_abc, best_fitness_abc = abc.train()\n",
    "abc_time = time.time() - start_time\n",
    "best_lr_abc, best_dropout_abc = best_solution_abc\n",
    "\n",
    "# **Train Model 2: Using GA**\n",
    "start_time = time.time()\n",
    "var_bound = np.array([[0.0001, 0.01], [0.1, 0.5]])\n",
    "algorithm_param = {'max_num_iteration': 5, 'population_size': 10, 'mutation_probability': 0.1, 'elit_ratio': 0.01, 'crossover_probability': 0.5, 'parents_portion': 0.3, 'crossover_type': 'uniform', 'max_iteration_without_improv': 2}\n",
    "model_ga = ga(function=train_and_evaluate, dimension=2, variable_type='real', variable_boundaries=var_bound, algorithm_parameters=algorithm_param)\n",
    "model_ga.run()\n",
    "ga_time = time.time() - start_time\n",
    "best_lr_ga, best_dropout_ga = model_ga.output_dict['variable']\n",
    "\n",
    "# **Train Model 3: Using GWO**\n",
    "start_time = time.time()\n",
    "gwo = OriginalGWO(obj_func=train_and_evaluate, lb=lb, ub=ub, problem_size=2, batch_size=5, epoch=5)\n",
    "best_solution_gwo, best_fitness_gwo = gwo.train()\n",
    "gwo_time = time.time() - start_time\n",
    "best_lr_gwo, best_dropout_gwo = best_solution_gwo\n",
    "\n",
    "# **Train Final Models Using Optimized Parameters**\n",
    "def build_and_train_model(learning_rate, dropout_rate, optimizer_name):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Bidirectional(LSTM(64, return_sequences=False)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)\n",
    "    model.save(f\"keyword_spotting_model_{optimizer_name}_1.h5\")\n",
    "    return history\n",
    "\n",
    "# Train Models\n",
    "history_abc = build_and_train_model(best_lr_abc, best_dropout_abc, \"abc\")\n",
    "history_ga = build_and_train_model(best_lr_ga, best_dropout_ga, \"ga\")\n",
    "history_gwo = build_and_train_model(best_lr_gwo, best_dropout_gwo, \"gwo\")\n",
    "\n",
    "# Compare Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(histories, names):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history, name in zip(histories, names):\n",
    "        plt.plot(history.history['val_accuracy'], label=f\"{name}\")\n",
    "    plt.title('Validation Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history, name in zip(histories, names):\n",
    "        plt.plot(history.history['val_loss'], label=f\"{name}\")\n",
    "    plt.title('Validation Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_results([history_abc, history_ga, history_gwo], [\"ABC\", \"GA\", \"GWO\"])\n",
    "\n",
    "# Print Training Times\n",
    "print(f\"ABC Training Time: {abc_time:.2f} sec\")\n",
    "print(f\"GA Training Time: {ga_time:.2f} sec\")\n",
    "print(f\"GWO Training Time: {gwo_time:.2f} sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfbfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e95b32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, y_train_sample = X_train[:len(X_train)//2], y_train[:len(y_train)//2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33803eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize the Artificial Bee Colony (ABC) optimizer\n",
      "Solve the problem\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'mode' is a string and value should be one of this: ['process', 'thread', 'swarm', 'single'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m abc \u001b[38;5;241m=\u001b[39m OriginalABC(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolve the problem\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m best_solution_abc \u001b[38;5;241m=\u001b[39m abc\u001b[38;5;241m.\u001b[39msolve(problem, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Extract best parameters\u001b[39;00m\n\u001b[0;32m     26\u001b[0m best_lr_abc, best_dropout_abc \u001b[38;5;241m=\u001b[39m best_solution_abc\u001b[38;5;241m.\u001b[39msolution\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\optimizer.py:224\u001b[0m, in \u001b[0;36mOptimizer.solve\u001b[1;34m(self, problem, mode, n_workers, termination, starting_solutions, seed)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    problem: an instance of Problem class or a dictionary\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    g_best: g_best, the best found agent, that hold the best solution and the best target. Access by: .g_best.solution, .g_best.target\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_problem(problem, seed)\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_mode_and_workers(mode, n_workers)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_termination(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, termination, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_variables()\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\optimizer.py:167\u001b[0m, in \u001b[0;36mOptimizer.check_mode_and_workers\u001b[1;34m(self, mode, n_workers)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_mode_and_workers\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode, n_workers):\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator\u001b[38;5;241m.\u001b[39mcheck_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSUPPORTED_MODES)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPARALLEL_MODES:\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_parallelizable:\n",
      "File \u001b[1;32m~\\anaconda3new\\Lib\\site-packages\\mealpy\\utils\\validator.py:70\u001b[0m, in \u001b[0;36mValidator.check_str\u001b[1;34m(self, name, value, bound)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m     69\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand value should be one of this: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a string \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: 'mode' is a string and value should be one of this: ['process', 'thread', 'swarm', 'single']."
     ]
    }
   ],
   "source": [
    "from mealpy.utils.problem import Problem\n",
    "from mealpy.swarm_based.ABC import OriginalABC\n",
    "from mealpy.utils.space import FloatVar\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the objective function\n",
    "def abc_objective(solution):\n",
    "    lr, dropout = solution  # Extract hyperparameters\n",
    "    return train_and_evaluate(solution, X_train_sample, y_train_sample, X_test, y_test)\n",
    "\n",
    "# Define the problem\n",
    "problem = Problem(\n",
    "    obj_func=abc_objective,\n",
    "    bounds=[FloatVar(0.0005, 0.01), FloatVar(0.1, 0.4)],  # Narrowed search space\n",
    "    minmax=\"min\",\n",
    "    log_to=None\n",
    ")\n",
    "\n",
    "print(\"Initialize the Artificial Bee Colony (ABC) optimizer\")\n",
    "abc = OriginalABC(epoch=50, pop_size=30, limit=5)\n",
    "\n",
    "print(\"Solve the problem\")\n",
    "best_solution_abc = abc.solve(problem, mode=\"multi\", n_workers=10)\n",
    "\n",
    "# Extract best parameters\n",
    "best_lr_abc, best_dropout_abc = best_solution_abc.solution\n",
    "print(f\"Best Learning Rate: {best_lr_abc}, Best Dropout: {best_dropout_abc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99c157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
